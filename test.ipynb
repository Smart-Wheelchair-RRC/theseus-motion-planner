{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_STATE = (0, 0, 0) # x, y, theta\n",
    "GOAL_POSITION = (0, 0) # x, y\n",
    "CELL_SIZE = 0.1\n",
    "SDF_ORIGIN = (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theseus as th\n",
    "from planner import MotionPlannerObjective\n",
    "import torch\n",
    "\n",
    "dtype = torch.double\n",
    "device = torch.device(\"cuda:0\")\n",
    "objective = MotionPlannerObjective(\n",
    "    total_time=60.0,\n",
    "    horizon=30,\n",
    "    current_velocity=torch.tensor([0.0, 0.0], dtype=dtype),\n",
    "    x_velocity_bounds=torch.tensor([-5, 5], dtype=dtype),\n",
    "    y_velocity_bounds=torch.tensor([-5, 5], dtype=dtype),\n",
    "    x_acceleration_bounds=torch.tensor([-5, 5], dtype=dtype),\n",
    "    y_acceleration_bounds=torch.tensor([-5, 5], dtype=dtype),\n",
    "    robot_radius=0.5, # REPLACE WITH ACTUAL RADIUS\n",
    "    safety_distance=0.1, # REPLACE WITH ACTUAL SAFETY DISTANCE\n",
    "    local_map_size=128, # REPLACE WITH ACTUAL MAP SIZE\n",
    ")\n",
    "\n",
    "optimizer = th.LevenbergMarquardt(\n",
    "    objective,\n",
    "    th.CholeskyDenseSolver,\n",
    "    max_iterations=50,\n",
    "    step_size=1.0,\n",
    ")\n",
    "motion_planner = th.TheseusLayer(optimizer)\n",
    "motion_planner.to(torch.device(\"cuda:0\"), dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_straight_line_inputs(start: torch.Tensor, goal: torch.Tensor, total_time, horizon):\n",
    "    # Returns a dictionary with state and acceleration variable names associated to a \n",
    "    # straight line trajectory between start and goal in SE(2) space\n",
    "    \n",
    "    # Calculate start and goal positions\n",
    "    start_pos = start[..., :2]  # Extracting the 2D position from SE(2)\n",
    "    goal_pos = goal  # Assuming goal is already a 2D point\n",
    "    \n",
    "    # Calculate distances and average accelerations for each batch element\n",
    "    start_goal_dist = goal_pos - start_pos  # Shape: (batch_size, 2)\n",
    "    avg_acc = 2 * start_goal_dist / (total_time**2)  # Shape: (batch_size, 2)\n",
    "    unit_horizon = start_goal_dist / (horizon - 1)  # Shape: (batch_size, 2)\n",
    "    \n",
    "    # Create input dictionary\n",
    "    input_dict = {}\n",
    "    \n",
    "    for i in range(horizon + 1):\n",
    "        state_i = start_pos + unit_horizon * i  # Shape: (batch_size, 2)\n",
    "        input_dict[f\"state_{i}\"] = torch.concat([state_i, start[..., 2:]], dim=-1)  # Concatenate the 2D position with the orientation\n",
    "        \n",
    "        if i == horizon:\n",
    "            continue\n",
    "        \n",
    "        if i == 0 or i == horizon - 1:\n",
    "            acceleration_i = torch.zeros_like(avg_acc)  # Zero acceleration at start and end\n",
    "        else:\n",
    "            acceleration_i = avg_acc\n",
    "        \n",
    "        input_dict[f\"acceleration_{i}\"] = acceleration_i\n",
    "        \n",
    "    return input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_inputs = {\n",
    "    'sdf_data': torch.zeros([128, 128], dtype=dtype).unsqueeze(0).to(device), # REPLACE WITH SDF DATA\n",
    "    'sdf_origin': torch.tensor([SDF_ORIGIN[0], SDF_ORIGIN[1]], dtype=dtype).unsqueeze(0).to(device),\n",
    "    'cell_size': torch.tensor([CELL_SIZE], dtype=dtype).unsqueeze(0).to(device),\n",
    "    'current_state': torch.tensor([CURRENT_STATE[0], CURRENT_STATE[1], torch.cos(CURRENT_STATE[2]), torch.sin(CURRENT_STATE[2])], dtype=dtype).unsqueeze(0).to(device),\n",
    "    'goal_position': torch.tensor([GOAL_POSITION[0], GOAL_POSITION[1]], dtype=dtype).unsqueeze(0).to(device),\n",
    "}\n",
    "planner_inputs.update(get_straight_line_inputs(\n",
    "    planner_inputs['current_state'], planner_inputs['goal_position'], 60.0, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonlinear optimizer. Iteration: 0. Error: 12628911.602194458\n",
      "Nonlinear optimizer. Iteration: 1. Error: 3291685.0078109805\n",
      "Nonlinear optimizer. Iteration: 2. Error: 3291636.0657504573\n",
      "Nonlinear optimizer. Iteration: 3. Error: 3291635.5264588045\n",
      "Nonlinear optimizer. Iteration: 4. Error: 3291635.527780474\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    final_values, info = motion_planner.forward(\n",
    "        planner_inputs,\n",
    "        optimizer_kwargs={\n",
    "            \"track_best_solution\": True,\n",
    "            \"verbose\": True,\n",
    "            \"damping\": 0.1,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state_1': tensor([[4.5589, 4.5566, 1.0000, 0.0000]], dtype=torch.float64),\n",
       " 'state_2': tensor([[7.5862, 7.6085, 1.0000, 0.0000]], dtype=torch.float64),\n",
       " 'state_3': tensor([[9.3742, 9.4093, 1.0000, 0.0000]], dtype=torch.float64),\n",
       " 'state_4': tensor([[10.2338, 10.2674,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_5': tensor([[10.5139, 10.5387,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_6': tensor([[10.4954, 10.5105,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_7': tensor([[10.3635, 10.3710,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_8': tensor([[10.2201, 10.2227,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_9': tensor([[10.1081, 10.1082,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_10': tensor([[10.0367, 10.0358,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_11': tensor([[9.9993, 9.9982, 1.0000, 0.0000]], dtype=torch.float64),\n",
       " 'state_12': tensor([[9.9847, 9.9838, 1.0000, 0.0000]], dtype=torch.float64),\n",
       " 'state_13': tensor([[9.9828, 9.9822, 1.0000, 0.0000]], dtype=torch.float64),\n",
       " 'state_14': tensor([[9.9864, 9.9860, 1.0000, 0.0000]], dtype=torch.float64),\n",
       " 'state_15': tensor([[9.9912, 9.9911, 1.0000, 0.0000]], dtype=torch.float64),\n",
       " 'state_16': tensor([[9.9953, 9.9953, 1.0000, 0.0000]], dtype=torch.float64),\n",
       " 'state_17': tensor([[9.9981, 9.9981, 1.0000, 0.0000]], dtype=torch.float64),\n",
       " 'state_18': tensor([[9.9997, 9.9997, 1.0000, 0.0000]], dtype=torch.float64),\n",
       " 'state_19': tensor([[10.0004, 10.0004,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_20': tensor([[10.0006, 10.0006,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_21': tensor([[10.0005, 10.0005,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_22': tensor([[10.0003, 10.0004,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_23': tensor([[10.0002, 10.0002,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_24': tensor([[10.0001, 10.0001,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_25': tensor([[10.0000, 10.0000,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_26': tensor([[10.0000, 10.0000,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_27': tensor([[10.0000, 10.0000,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_28': tensor([[10.0000, 10.0000,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_29': tensor([[10.0000, 10.0000,  1.0000,  0.0000]], dtype=torch.float64),\n",
       " 'state_30': tensor([[10., 10.,  1.,  0.]], dtype=torch.float64),\n",
       " 'acceleration_1': tensor([[1.4911, 1.5061]], dtype=torch.float64),\n",
       " 'acceleration_2': tensor([[0.9197, 0.9284]], dtype=torch.float64),\n",
       " 'acceleration_3': tensor([[0.4680, 0.4688]], dtype=torch.float64),\n",
       " 'acceleration_4': tensor([[0.1736, 0.1702]], dtype=torch.float64),\n",
       " 'acceleration_5': tensor([[0.0140, 0.0096]], dtype=torch.float64),\n",
       " 'acceleration_6': tensor([[-0.0526, -0.0562]], dtype=torch.float64),\n",
       " 'acceleration_7': tensor([[-0.0656, -0.0681]], dtype=torch.float64),\n",
       " 'acceleration_8': tensor([[-0.0543, -0.0557]], dtype=torch.float64),\n",
       " 'acceleration_9': tensor([[-0.0362, -0.0368]], dtype=torch.float64),\n",
       " 'acceleration_10': tensor([[-0.0199, -0.0201]], dtype=torch.float64),\n",
       " 'acceleration_11': tensor([[-0.0085, -0.0084]], dtype=torch.float64),\n",
       " 'acceleration_12': tensor([[-0.0018, -0.0017]], dtype=torch.float64),\n",
       " 'acceleration_13': tensor([[0.0012, 0.0014]], dtype=torch.float64),\n",
       " 'acceleration_14': tensor([[0.0021, 0.0022]], dtype=torch.float64),\n",
       " 'acceleration_15': tensor([[0.0020, 0.0020]], dtype=torch.float64),\n",
       " 'acceleration_16': tensor([[0.0014, 0.0014]], dtype=torch.float64),\n",
       " 'acceleration_17': tensor([[0.0008, 0.0008]], dtype=torch.float64),\n",
       " 'acceleration_18': tensor([[0.0004, 0.0004]], dtype=torch.float64),\n",
       " 'acceleration_19': tensor([[0.0001, 0.0001]], dtype=torch.float64),\n",
       " 'acceleration_20': tensor([[-1.5551e-05, -2.0298e-05]], dtype=torch.float64),\n",
       " 'acceleration_21': tensor([[-6.5910e-05, -6.9312e-05]], dtype=torch.float64),\n",
       " 'acceleration_22': tensor([[-6.9424e-05, -7.1237e-05]], dtype=torch.float64),\n",
       " 'acceleration_23': tensor([[-5.3547e-05, -5.4118e-05]], dtype=torch.float64),\n",
       " 'acceleration_24': tensor([[-3.3894e-05, -3.3847e-05]], dtype=torch.float64),\n",
       " 'acceleration_25': tensor([[-1.7451e-05, -1.7535e-05]], dtype=torch.float64),\n",
       " 'acceleration_26': tensor([[-6.0340e-06, -7.0433e-06]], dtype=torch.float64),\n",
       " 'acceleration_27': tensor([[ 9.8644e-07, -1.6696e-06]], dtype=torch.float64),\n",
       " 'acceleration_28': tensor([[4.9066e-06, 2.0227e-07]], dtype=torch.float64),\n",
       " 'acceleration_29': tensor([[6.7174e-06, 3.1366e-07]], dtype=torch.float64),\n",
       " 'acceleration_0': tensor([[2.0167, 2.0209]], dtype=torch.float64),\n",
       " 'state_0': tensor([[0.2628, 0.2574, 1.0000, 0.0000]], dtype=torch.float64)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.best_solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "theseus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
